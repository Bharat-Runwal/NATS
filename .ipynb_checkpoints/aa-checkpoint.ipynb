{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import argparse\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "class SoftDotAttention(torch.nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size\n",
    "    ):\n",
    "        super(SoftDotAttention, self).__init__()\n",
    "        \n",
    "        self.linear_in = torch.nn.Linear(\n",
    "            hidden_size,\n",
    "            hidden_size,\n",
    "            bias=False\n",
    "        )\n",
    "        self.softmax_ = torch.nn.Softmax()\n",
    "        self.linear_out = torch.nn.Linear(\n",
    "            hidden_size*2,\n",
    "            hidden_size,\n",
    "            bias=False\n",
    "        )\n",
    "        self.tanh_ = torch.nn.Tanh()\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, input_, context):\n",
    "        \n",
    "        target = self.linear_in(input_).unsqueeze(2)\n",
    "        \n",
    "        print context.size()\n",
    "        attn = torch.bmm(context, target).squeeze(2)\n",
    "        attn = self.softmax_(attn)\n",
    "        \n",
    "        return \n",
    "\n",
    "rd1 = Variable(torch.rand([10, 4]))\n",
    "rd2 = Variable(torch.rand([10, 1, 4]))\n",
    "model = SoftDotAttention(hidden_size=4)\n",
    "model(rd1, rd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary size: 80475\n",
      "The number of batches: 1444\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../sum_data/'\n",
    "file_vocab = 'cnn_vocab.txt'\n",
    "file_corpus = 'cnn.txt'\n",
    "n_epoch = 20\n",
    "batch_size = 64\n",
    "\n",
    "vocab2id, id2vocab = construct_vocab(data_dir+'/'+file_vocab)\n",
    "print 'The vocabulary size: {0}'.format(len(vocab2id))\n",
    "\n",
    "n_batch = create_batch_file(file_name='../sum_data/cnn.txt', batch_size=batch_size)\n",
    "print 'The number of batches: {0}'.format(n_batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0 ,.,.) = \n",
      "  0.4524  0.3267  0.3612  0.1276\n",
      "  0.6911  0.1173  0.3906  0.4915\n",
      "  0.9775  0.8692  0.5464  0.2167\n",
      "\n",
      "(1 ,.,.) = \n",
      "  0.2498  0.3740  0.1371  0.4953\n",
      "  0.4477  0.2291  0.5946  0.0385\n",
      "  0.0595  0.2777  0.1282  0.1308\n",
      "\n",
      "(2 ,.,.) = \n",
      "  0.7180  0.2005  0.8887  0.6670\n",
      "  0.0028  0.6183  0.7131  0.9975\n",
      "  0.1788  0.4824  0.4547  0.1755\n",
      "\n",
      "(3 ,.,.) = \n",
      "  0.5316  0.5623  0.5602  0.2228\n",
      "  0.6682  0.2707  0.3992  0.0777\n",
      "  0.6053  0.4470  0.5499  0.4378\n",
      "\n",
      "(4 ,.,.) = \n",
      "  0.0915  0.0009  0.2707  0.0755\n",
      "  0.7214  0.4176  0.2227  0.4667\n",
      "  0.6829  0.3640  0.2738  0.2508\n",
      "\n",
      "(5 ,.,.) = \n",
      "  0.7206  0.4302  0.2738  0.6968\n",
      "  0.7333  0.9302  0.1618  0.2182\n",
      "  0.3929  0.8321  0.7250  0.5763\n",
      "\n",
      "(6 ,.,.) = \n",
      "  0.6652  0.3046  0.0167  0.8674\n",
      "  0.3814  0.1642  0.9405  0.2781\n",
      "  0.9898  0.8735  0.5222  0.4309\n",
      "\n",
      "(7 ,.,.) = \n",
      "  0.5327  0.0764  0.6956  0.4435\n",
      "  0.9135  0.8709  0.1748  0.1000\n",
      "  0.3046  0.4527  0.0751  0.4540\n",
      "\n",
      "(8 ,.,.) = \n",
      "  0.3599  0.8564  0.3116  0.6819\n",
      "  0.2630  0.5872  0.0581  0.8738\n",
      "  0.9057  0.8298  0.6223  0.6964\n",
      "\n",
      "(9 ,.,.) = \n",
      "  0.4747  0.5113  0.1579  0.5506\n",
      "  0.8244  0.4299  0.9851  0.6679\n",
      "  0.2728  0.7524  0.1544  0.5604\n",
      "[torch.FloatTensor of size 10x3x4]\n",
      "\n",
      "\n",
      "(0 ,.,.) = \n",
      "  0.9234  0.5292  0.5342  0.9437  0.5002\n",
      "  0.5091  0.4063  0.7384  0.7919  0.8313\n",
      "  0.4877  0.1020  0.9152  0.7887  0.6800\n",
      "\n",
      "(1 ,.,.) = \n",
      "  0.4540  0.7985  0.5618  0.9952  0.0114\n",
      "  0.5331  0.5020  0.4148  0.5241  0.4455\n",
      "  0.8084  0.1099  0.8999  0.9505  0.6561\n",
      "\n",
      "(2 ,.,.) = \n",
      "  0.6284  0.9971  0.6055  0.3082  0.2288\n",
      "  0.9764  0.0021  0.6280  0.2671  0.3800\n",
      "  0.0710  0.6256  0.8445  0.6524  0.9350\n",
      "\n",
      "(3 ,.,.) = \n",
      "  0.1997  0.3623  0.5476  0.2653  0.2570\n",
      "  0.4270  0.2667  0.7277  0.0425  0.6057\n",
      "  0.4693  0.7568  0.5659  0.7761  0.9482\n",
      "\n",
      "(4 ,.,.) = \n",
      "  0.1814  0.6622  0.0646  0.5165  0.8559\n",
      "  0.4589  0.4485  0.5481  0.4323  0.4356\n",
      "  0.0831  0.6459  0.5109  0.3624  0.8981\n",
      "\n",
      "(5 ,.,.) = \n",
      "  0.0478  0.5292  0.3339  0.0292  0.3525\n",
      "  0.5155  0.0381  0.5564  0.5412  0.2734\n",
      "  0.1010  0.1461  0.3119  0.6187  0.1288\n",
      "\n",
      "(6 ,.,.) = \n",
      "  0.0741  0.9033  0.6035  0.1095  0.2640\n",
      "  0.1763  0.8006  0.1907  0.6215  0.9406\n",
      "  0.5986  0.3568  0.1800  0.9102  0.8884\n",
      "\n",
      "(7 ,.,.) = \n",
      "  0.7719  0.9924  0.7410  0.9021  0.4205\n",
      "  0.7675  0.6622  0.0184  0.7000  0.8742\n",
      "  0.8957  0.8432  0.8320  0.6551  0.1221\n",
      "\n",
      "(8 ,.,.) = \n",
      "  0.4207  0.0323  0.9538  0.1614  0.5147\n",
      "  0.4307  0.9214  0.0688  0.3785  0.3356\n",
      "  0.6957  0.4377  0.4797  0.2868  0.2107\n",
      "\n",
      "(9 ,.,.) = \n",
      "  0.8630  0.4479  0.2887  0.5391  0.5851\n",
      "  0.0799  0.4794  0.3877  0.0736  0.5948\n",
      "  0.9951  0.9621  0.1712  0.5578  0.4385\n",
      "[torch.FloatTensor of size 10x3x5]\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "torch.mm received an invalid combination of arguments - got (torch.FloatTensor, Variable), but expected one of:\n * (torch.FloatTensor source, torch.FloatTensor mat2)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mtorch.FloatTensor\u001b[0m, \u001b[31;1mVariable\u001b[0m)\n * (torch.SparseFloatTensor source, torch.FloatTensor mat2)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.FloatTensor\u001b[0m, \u001b[31;1mVariable\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-908bc22ffa54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mrd2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSoftDotAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrd1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrd2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m '''\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-908bc22ffa54>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_, context)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;31m#attn = torch.bmm(context, target).squeeze(2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m#attn = self.softmax_(attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/linear.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/tensor.pyc\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         See :func:`torch.matmul`.\"\"\"\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/functional.pyc\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(tensor1, tensor2, out)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_contiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: torch.mm received an invalid combination of arguments - got (torch.FloatTensor, Variable), but expected one of:\n * (torch.FloatTensor source, torch.FloatTensor mat2)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mtorch.FloatTensor\u001b[0m, \u001b[31;1mVariable\u001b[0m)\n * (torch.SparseFloatTensor source, torch.FloatTensor mat2)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.FloatTensor\u001b[0m, \u001b[31;1mVariable\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "class SoftDotAttention(torch.nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size\n",
    "    ):\n",
    "        super(SoftDotAttention, self).__init__()\n",
    "        \n",
    "        self.linear_in = torch.nn.Linear(\n",
    "            hidden_size,\n",
    "            hidden_size,\n",
    "            bias=False\n",
    "        )\n",
    "        self.softmax_ = torch.nn.Softmax()\n",
    "        self.linear_out = torch.nn.Linear(\n",
    "            hidden_size*2,\n",
    "            hidden_size,\n",
    "            bias=False\n",
    "        )\n",
    "        self.tanh_ = torch.nn.Tanh()\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, input_, context):\n",
    "        \n",
    "        print input_\n",
    "        print context\n",
    "        target = self.linear_in(input_)\n",
    "        #attn = torch.bmm(context, target).squeeze(2)\n",
    "        #attn = self.softmax_(attn)\n",
    "        \n",
    "        return\n",
    "\n",
    "rd1 = torch.rand([10, 3, 4])\n",
    "rd2 = torch.rand([10, 3, 5])\n",
    "model = SoftDotAttention(hidden_size=10)\n",
    "model(rd1, rd2)\n",
    "        \n",
    "'''\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      "  1\n",
      "  2\n",
      "\n",
      "(1 ,.,.) = \n",
      "  3\n",
      "  4\n",
      "[torch.LongTensor of size 2x2x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "db = Variable(torch.LongTensor([[1,2],[3,4]]))\n",
    "db = db.unsqueeze(2)\n",
    "print db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq2seqAttention (\n",
      "  (src_embedding): Embedding(999, 100, padding_idx=0)\n",
      "  (trg_embedding): Embedding(999, 100, padding_idx=0)\n",
      "  (encoder): LSTM(100, 25, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (decoder): LSTMAttentionDot (\n",
      "  )\n",
      "  (encoder2decoder): Linear (50 -> 50)\n",
      "  (decoder2vocab): Linear (50 -> 999)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LSTMAttentionDot(torch.nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        num_layers=1,\n",
    "        batch_first=True\n",
    "    ):\n",
    "        super(LSTMAttentionDot, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layer = num_layers\n",
    "        \n",
    "    def forward(self):\n",
    "        \n",
    "        \n",
    "        return\n",
    "    \n",
    "\n",
    "class seq2seqAttention(torch.nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        src_emb_dim=100,\n",
    "        trg_emb_dim=100,\n",
    "        src_hidden_dim=50,\n",
    "        trg_hidden_dim=50,\n",
    "        src_vocab_size=999,\n",
    "        trg_vocab_size=999,\n",
    "        src_pad_token=0,\n",
    "        trg_pad_token=0,\n",
    "        src_nlayer=2,\n",
    "        trg_nlayer=1,\n",
    "        batch_first=True,\n",
    "        src_bidirect=True,\n",
    "        batch_size=128,\n",
    "        dropout=0.0\n",
    "    ):\n",
    "        super(seq2seqAttention, self).__init__()\n",
    "        # parameters\n",
    "        self.src_emb_dim = src_emb_dim\n",
    "        self.trg_emb_dim = trg_emb_dim\n",
    "        self.src_hidden_dim = src_hidden_dim\n",
    "        self.trg_hidden_dim = trg_hidden_dim\n",
    "        self.src_vocab_size = src_vocab_size\n",
    "        self.trg_vocab_size = trg_vocab_size\n",
    "        self.src_nlayer = src_nlayer\n",
    "        self.trg_nlayer = trg_nlayer\n",
    "        self.batch_first = batch_first\n",
    "        self.src_bidirect = src_bidirect\n",
    "        self.batch_size = batch_size\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.src_num_directions = 1\n",
    "        if self.src_bidirect:\n",
    "            self.src_hidden_dim = src_hidden_dim // 2\n",
    "            self.src_num_directions = 2\n",
    "        \n",
    "        \n",
    "        # source embedding\n",
    "        self.src_embedding = torch.nn.Embedding(\n",
    "            self.src_vocab_size,\n",
    "            self.src_emb_dim,\n",
    "            padding_idx=0\n",
    "        ).cuda()\n",
    "        torch.nn.init.normal(\n",
    "            self.src_embedding.weight, \n",
    "            mean=0.0, \n",
    "            std=0.02\n",
    "        )\n",
    "        # targe embedding\n",
    "        self.trg_embedding = torch.nn.Embedding(\n",
    "            self.trg_vocab_size,\n",
    "            self.trg_emb_dim,\n",
    "            padding_idx=0\n",
    "        ).cuda()\n",
    "        torch.nn.init.normal(\n",
    "            self.trg_embedding.weight,\n",
    "            mean=0.0,\n",
    "            std=0.02\n",
    "        )\n",
    "        # encoder\n",
    "        self.encoder = torch.nn.LSTM(\n",
    "            input_size=self.src_emb_dim,\n",
    "            hidden_size=self.src_hidden_dim,\n",
    "            num_layers=self.src_nlayer,\n",
    "            batch_first=self.batch_first,\n",
    "            dropout=self.dropout,\n",
    "            bidirectional=self.src_bidirect\n",
    "        ).cuda()\n",
    "        # decoder\n",
    "        self.decoder = LSTMAttentionDot(\n",
    "            input_size=self.trg_emb_dim,\n",
    "            hidden_size=self.trg_hidden_dim,\n",
    "            batch_first=self.batch_first\n",
    "        ).cuda()\n",
    "        \n",
    "        # encoder to decoder\n",
    "        self.encoder2decoder = torch.nn.Linear(\n",
    "            self.src_hidden_dim*self.src_num_directions,\n",
    "            self.trg_hidden_dim\n",
    "        ).cuda()\n",
    "        torch.nn.init.constant(self.encoder2decoder.bias, 0.0)\n",
    "        # decoder to vocab\n",
    "        self.decoder2vocab = torch.nn.Linear(\n",
    "            self.trg_hidden_dim,\n",
    "            self.trg_vocab_size\n",
    "        ).cuda()\n",
    "        torch.nn.init.constant(self.decoder2vocab.bias, 0.0)\n",
    "        \n",
    "        \n",
    "    def forward(self, input_src, input_trg):\n",
    "        \n",
    "        src_emb = self.src_embedding(input_src)\n",
    "        trg_emb = self.trg_embedding(input_trg)\n",
    "        \n",
    "        batch_size = input_src.size(1)\n",
    "        if self.batch_first:\n",
    "            batch_size = input_src.size(0)\n",
    "        \n",
    "        \n",
    "        return\n",
    "    \n",
    "\n",
    "model = seq2seqAttention(\n",
    "    src_emb_dim=100,\n",
    "    trg_emb_dim=100,\n",
    "    src_hidden_dim=50,\n",
    "    trg_hidden_dim=50,\n",
    "    src_vocab_size=999,\n",
    "    trg_vocab_size=999,\n",
    "    src_pad_token=0,\n",
    "    trg_pad_token=0,\n",
    "    src_nlayer=2,\n",
    "    trg_nlayer=1,\n",
    "    batch_first=True,\n",
    "    src_bidirect=True,\n",
    "    batch_size=128,\n",
    "    dropout=0.0\n",
    ").cuda()\n",
    "\n",
    "print model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  0.0211 -0.3651  0.1108  0.3598 -0.3875\n",
      "  0.0275 -0.2466  0.0341  0.2917 -0.3483\n",
      "  0.0078 -0.2312  0.0158  0.2223 -0.3095\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.0699  0.1139  0.1981  0.0016 -0.0328\n",
      " -0.1103 -0.1088  0.1511  0.1077 -0.1658\n",
      " -0.0740 -0.1974  0.0971  0.1326 -0.1945\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.3790 -0.1426 -0.0775  0.1659 -0.0138\n",
      "  0.3755 -0.1742 -0.0582  0.1803 -0.1413\n",
      "  0.3145 -0.2018 -0.0543  0.1971 -0.2046\n",
      "... \n",
      "\n",
      "(125,.,.) = \n",
      "  0.3470 -0.2297  0.0341  0.1668  0.4335\n",
      "  0.2763 -0.2408 -0.0086  0.1682  0.0028\n",
      "  0.2504 -0.2368 -0.0259  0.1880 -0.1519\n",
      "\n",
      "(126,.,.) = \n",
      "  0.2607  0.2660 -0.0684  0.0171  0.1855\n",
      "  0.2927 -0.0162 -0.0672  0.1126 -0.1025\n",
      "  0.1651 -0.1295 -0.0594  0.1403 -0.2193\n",
      "\n",
      "(127,.,.) = \n",
      " -0.3533  0.0429  0.2430  0.0829 -0.1130\n",
      " -0.3496 -0.1197  0.2393  0.1530 -0.1557\n",
      " -0.2414 -0.1981  0.1626  0.1459 -0.1721\n",
      "[torch.FloatTensor of size 128x3x5]\n",
      "\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.0542  0.0632  0.0649 -0.2556 -0.2321\n",
      "  0.1586  0.4667  0.1472 -0.0829 -0.2356\n",
      " -0.1051  0.1526  0.3446  0.2156  0.1200\n",
      "                   ⋮                    \n",
      " -0.1850  0.0314  0.3350 -0.0238  0.2158\n",
      "  0.0058 -0.1909  0.0087 -0.4076  0.2615\n",
      "  0.1865  0.5324  0.1082 -0.0808 -0.4039\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0078 -0.2312  0.0158  0.2223 -0.3095\n",
      " -0.0740 -0.1974  0.0971  0.1326 -0.1945\n",
      "  0.3145 -0.2018 -0.0543  0.1971 -0.2046\n",
      "                   ⋮                    \n",
      "  0.2504 -0.2368 -0.0259  0.1880 -0.1519\n",
      "  0.1651 -0.1295 -0.0594  0.1403 -0.2193\n",
      " -0.2414 -0.1981  0.1626  0.1459 -0.1721\n",
      "[torch.FloatTensor of size 2x128x5]\n",
      "\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.0900  0.1026  0.1005 -0.6442 -0.3032\n",
      "  0.3507  0.8830  0.3877 -0.2179 -0.3878\n",
      " -0.3347  0.2660  0.4295  0.3397  0.2827\n",
      "                   ⋮                    \n",
      " -0.2851  0.0489  0.5811 -0.0811  0.2436\n",
      "  0.0109 -0.3215  0.0101 -0.6537  0.4299\n",
      "  0.4661  0.9745  0.3225 -0.4155 -0.5020\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0161 -0.5343  0.0368  0.6431 -0.7167\n",
      " -0.1516 -0.4193  0.2150  0.3252 -0.4030\n",
      "  0.8150 -0.4667 -0.1196  0.5839 -0.5024\n",
      "                   ⋮                    \n",
      "  0.5995 -0.5311 -0.0546  0.5662 -0.3790\n",
      "  0.3530 -0.2795 -0.1229  0.3612 -0.5422\n",
      " -0.5202 -0.4181  0.3797  0.3556 -0.3296\n",
      "[torch.FloatTensor of size 2x128x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnn = torch.nn.LSTM(9, 5, num_layers=2, batch_first=True)\n",
    "\n",
    "input = Variable(torch.randn(128, 3, 9))\n",
    "h0 = Variable(torch.randn(2, 128, 5))\n",
    "c0 = Variable(torch.randn(2, 128, 5))\n",
    "output, hn = rnn(input, (h0, c0))\n",
    "print output\n",
    "print hn[0]\n",
    "print hn[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
