{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import torch\n",
    "\n",
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../sum_data/seq2seq_results-1/seq2seq_9_500.pt\n"
     ]
    }
   ],
   "source": [
    "file_names = glob.glob('../sum_data/seq2seq_results-1/*pt')\n",
    "file_names = sorted(file_names)\n",
    "print file_names[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq (\n",
      "  (softmax_): Softmax ()\n",
      "  (tanh_): Tanh ()\n",
      "  (sigmoid_): Sigmoid ()\n",
      "  (embedding): Embedding(80475, 100, padding_idx=0)\n",
      "  (encoder): GRU(100, 50, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (decoder): GRUDecoder (\n",
      "    (softmax_): Softmax ()\n",
      "    (tanh_): Tanh ()\n",
      "    (sigmoid_): Sigmoid ()\n",
      "    (gru_): GRUCell(200, 100)\n",
      "    (attn_layer): AttentionBahdanau (\n",
      "      (softmax_): Softmax ()\n",
      "      (tanh_): Tanh ()\n",
      "    )\n",
      "  )\n",
      "  (encoder2decoder): Linear (100 -> 100)\n",
      "  (decoder2vocab): Linear (100 -> 80475)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(file_names[-1])\n",
    "print model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary size: 80475\n",
      "The number of batches: 1444\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../sum_data/'\n",
    "file_vocab = 'cnn_vocab.txt'\n",
    "file_corpus = 'cnn.txt'\n",
    "batch_size = 64\n",
    "\n",
    "vocab2id, id2vocab = construct_vocab(data_dir+'/'+file_vocab)\n",
    "print 'The vocabulary size: {0}'.format(len(vocab2id))\n",
    "\n",
    "if not os.path.exists('batch_folder'):\n",
    "    n_batch = create_batch_file(\n",
    "        file_name=data_dir+'/'+file_corpus, \n",
    "        batch_size=batch_size\n",
    "    )\n",
    "else:\n",
    "    n_batch = len(glob.glob('batch_folder/batch_*'))\n",
    "print 'The number of batches: {0}'.format(n_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "--------------------------------------------------\n",
      ": u.s. a a a a a a a the the the the and and and and and and and and and and and and and and and and ,\n",
      "--------------------------------------------------\n",
      "eruptions began at mount lokon in noth sulawesi province on friday . loud , explosive eruptions sunday prompt authorities to put all on alert , an official says .\n",
      "--------------------------------------------------\n",
      "<s> fresh lava and ash spewed sunday from a volcano in northeast indonesia , casting haze over the crater and prompting authorities to warn nearby residents , state news reported . loud , thumping noises were heard at a monitoring post 6 kilometers ( 3.8 miles ) from where mount lokon erupted around 2:05 p.m. ( 2:05 a.m . et ) sunday , said <unk> purwo nugroho of indonesia 's national disaster mitigation board , as reported by the official antara news agency . read more : the supervolcano that could threaten earth the volatile activity continued after that , though authorities could not immediately ascertain how many additional , separate eruptions had occurred . `` right now , there are still eruptions , but they could not be observed as the volcano is covered by haze , '' said nugroho . those living within 2.5 kilometers ( 1.5 miles ) of the volcano , which is in the pacific island nation 's north sulawesi province , are being told to limit outdoor activity , according to nugroho , who heads the mitigation board 's data and information center . the volcano has been active since last friday , with some eruptions spewing ash 1,500 meters into the air . one day earlier , officials issued an early warning to residents -- yet mount lokon was still categorized as idle until sunday , as it is now on alert status . indonesia is on the `` ring of fire , '' an arc of fault\n"
     ]
    }
   ],
   "source": [
    "src_var, trg_input_var, trg_output_var = process_minibatch(\n",
    "    300, vocab2id, max_lens=[256, 30]\n",
    ")\n",
    "\n",
    "\n",
    "trg_input_arr = [[vocab2id['<s>'] for k in range(30)] for j in range(batch_size)]\n",
    "trg_input_var = Variable(torch.LongTensor(trg_input_arr))\n",
    "for k in range(30):\n",
    "    print k\n",
    "    logits = model(src_var.cuda(), trg_input_var.cuda())\n",
    "    word_prob = model.decode(logits).data.cpu().numpy().argmax(axis=-1)\n",
    "    for j in range(64):\n",
    "        trg_input_arr[j][k] = word_prob[j][k]\n",
    "        trg_input_var = Variable(torch.LongTensor(trg_input_arr))\n",
    "\n",
    "idid = 0\n",
    "sen_pred = [id2vocab[x] for x in word_prob[idid]]\n",
    "print ''.join(['-' for k in range(50)])\n",
    "st_idx = len(sen_pred)\n",
    "for k, wd in enumerate(sen_pred):\n",
    "    if wd == '</s>':\n",
    "        st_idx = k\n",
    "        break\n",
    "sen_pred = sen_pred[:st_idx]\n",
    "print ' '.join(sen_pred)\n",
    "\n",
    "print ''.join(['-' for k in range(50)])\n",
    "sen_abs = [id2vocab[x] for x in trg_output_var.data[idid]]\n",
    "st_idx = len(sen_abs)\n",
    "for k, wd in enumerate(sen_abs):\n",
    "    if wd == '<pad>':\n",
    "\tst_idx = k\n",
    "\tbreak\n",
    "print ' '.join(sen_abs[:st_idx])\n",
    "\n",
    "print ''.join(['-' for k in range(50)])\n",
    "sen_source = [id2vocab[x] for x in src_var.data[idid]]\n",
    "st_idx = len(sen_source)\n",
    "for k, wd in enumerate(sen_source):\n",
    "    if wd == '<pad>':\n",
    "\tst_idx = k\n",
    "\tbreak\n",
    "print ' '.join(sen_source[:st_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def beam_search(\n",
    "    model, \n",
    "    src_text,\n",
    "    vocab_,\n",
    "    beam_size=3, \n",
    "    max_len=30\n",
    "):\n",
    "    batch_size = src_text.size()\n",
    "    trg_text = Variable(torch.LongTensor())\n",
    "    model(src_text.cuda(), )\n",
    "    return trg_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "Columns 0 to 12 \n",
       "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
       "\n",
       "Columns 13 to 19 \n",
       "    2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2\n",
       "[torch.LongTensor of size 10x20]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor(10, 20) * 0 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
