{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import shutil\n",
    "import re\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#from seq2seq import *\n",
    "#from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_vocab(file_, mincount=10):\n",
    "    vocab2id = {\n",
    "        '<s>': 0,\n",
    "        '</s>': 1,\n",
    "        '<pad>': 2,\n",
    "        '<unk>': 3\n",
    "    }\n",
    "    \n",
    "    id2vocab = {\n",
    "        0: '<s>',\n",
    "        1: '</s>',\n",
    "        2: '<pad>',\n",
    "        3: '<unk>'\n",
    "    }\n",
    "    cnt = 4\n",
    "    with open(file_, 'r') as fp:\n",
    "        for line in fp:\n",
    "            arr = re.split('<sec>', line[:-1])\n",
    "            if int(arr[1]) >= mincount:\n",
    "                vocab2id[arr[0]] = cnt\n",
    "                id2vocab[cnt] = arr[0]\n",
    "                cnt += 1\n",
    "    \n",
    "    return vocab2id, id2vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_file(file_name, batch_size):\n",
    "    folder = 'batch_folder'\n",
    "    fkey = 'batch_'\n",
    "    if os.path.exists(folder):\n",
    "        shutil.rmtree(folder)\n",
    "    os.mkdir(folder)\n",
    "    \n",
    "    fp = open(file_name, 'r')\n",
    "    cnt = 0\n",
    "    for line in fp:\n",
    "        try:\n",
    "            arr.append(line)\n",
    "        except:\n",
    "            arr = []\n",
    "        if len(arr) == batch_size:\n",
    "            fout = open(folder+'/'+fkey+str(cnt), 'w')\n",
    "            for itm in arr:\n",
    "                fout.write(itm)\n",
    "            fout.close()\n",
    "            arr = []\n",
    "            cnt += 1\n",
    "    fp.close()\n",
    "    \n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_minibatch(batch_id, vocab2id, max_lens=[512, 64]):\n",
    "    \n",
    "    folder = 'batch_folder'\n",
    "    fkey = 'batch_'\n",
    "    file_ = folder + '/' + fkey + str(batch_id)\n",
    "    fp = open(file_, 'r')\n",
    "    src_arr = []\n",
    "    trg_arr = []\n",
    "    for line in fp:\n",
    "        arr = re.split('<sec>', line[:-1])\n",
    "            \n",
    "        dabs = re.split('<pg>|<st>', arr[2])\n",
    "        for j in range(len(dabs)):\n",
    "            dabs[j] += '.'\n",
    "        dabs = ''.join(dabs)\n",
    "        dabs = re.split('\\s', dabs)\n",
    "        dabs = filter(None, dabs)\n",
    "        dabs = ['<s>'] + dabs + ['</s>']\n",
    "        dabs2id = [\n",
    "            vocab2id[wd] if wd in vocab2id\n",
    "            else vocab2id['<unk>']\n",
    "            for wd in dabs\n",
    "        ]\n",
    "        trg_arr.append(dabs2id)\n",
    "        \n",
    "        dart = ''.join(re.split('<pg>|<st>', arr[3]))\n",
    "        dart = re.split('\\s', dart)\n",
    "        dart = filter(None, dart)\n",
    "        dart = ['<s>'] + dart + ['</s>']\n",
    "        dart2id = [\n",
    "            vocab2id[wd] if wd in vocab2id\n",
    "            else vocab2id['<unk>']\n",
    "            for wd in dart\n",
    "        ]\n",
    "        src_arr.append(dart2id)\n",
    "    fp.close()\n",
    "    \n",
    "    src_arr = [itm[:max_lens[0]] for itm in src_arr]\n",
    "    trg_arr = [itm[:max_lens[1]] for itm in trg_arr]\n",
    "    \n",
    "    #src_lens = [len(itm) for itm in src_arr]\n",
    "    #trg_lens = [len(itm) for itm in trg_arr]\n",
    "    #max_lens = [max(src_lens), max(trg_lens)]\n",
    "\n",
    "    src_arr = [\n",
    "        itm[:-1] + [vocab2id['<pad>']]*(1+max_lens[0]-len(itm))\n",
    "        for itm in src_arr\n",
    "    ]\n",
    "    trg_input_arr = [\n",
    "        itm[:-1] + [vocab2id['<pad>']]*(1+max_lens[1]-len(itm))\n",
    "        for itm in trg_arr\n",
    "    ]\n",
    "    trg_output_arr = [\n",
    "        itm[1:] + [vocab2id['<pad>']]*(1+max_lens[1]-len(itm))\n",
    "        for itm in trg_arr\n",
    "    ]\n",
    "    \n",
    "    src_var = Variable(torch.LongTensor(src_arr))\n",
    "    trg_input_var = Variable(torch.LongTensor(trg_input_arr))\n",
    "    trg_output_var = Variable(torch.LongTensor(trg_output_arr))\n",
    "    \n",
    "    return src_var, trg_input_var, trg_output_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class seq2seq(torch.nn.Module):\n",
    "    '''\n",
    "    LSTM encoder\n",
    "    LSTM decoder\n",
    "    '''\n",
    "    def __init__(\n",
    "        self,\n",
    "        src_emb_dim=100,\n",
    "        trg_emb_dim=100,\n",
    "        src_hidden_dim=25,\n",
    "        trg_hidden_dim=50,\n",
    "        src_vocab_size=999,\n",
    "        trg_vocab_size=999,\n",
    "        src_pad_token=0,\n",
    "        trg_pad_token=0,\n",
    "        src_nlayer=2,\n",
    "        trg_nlayer=1,\n",
    "        src_bidirect=True,\n",
    "        batch_size=128,\n",
    "        dropout=0.0\n",
    "    ):\n",
    "        super(seq2seq, self).__init__()\n",
    "        \n",
    "        self.src_bidirect = src_bidirect\n",
    "        self.trg_vocab_size = trg_vocab_size\n",
    "\n",
    "        self.n_directions = 1\n",
    "        self.src_hidden_dim = src_hidden_dim//2\n",
    "        if src_bidirect:\n",
    "            self.n_directions = 2\n",
    "            self.src_hidden_dim = src_hidden_dim\n",
    "        \n",
    "        self.src_embedding = torch.nn.Embedding(\n",
    "            src_vocab_size,\n",
    "            src_emb_dim,\n",
    "            padding_idx=0\n",
    "        ).cuda()\n",
    "        \n",
    "        self.trg_embedding = torch.nn.Embedding(\n",
    "            trg_vocab_size,\n",
    "            trg_emb_dim,\n",
    "            padding_idx=0\n",
    "        ).cuda()\n",
    "        \n",
    "        self.encoder = torch.nn.LSTM(\n",
    "            input_size=src_emb_dim,\n",
    "            hidden_size=src_hidden_dim,\n",
    "            num_layers=src_nlayer,\n",
    "            bidirectional=src_bidirect,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        ).cuda()\n",
    "        \n",
    "        self.decoder = torch.nn.LSTM(\n",
    "            input_size=trg_emb_dim,\n",
    "            hidden_size=trg_hidden_dim,\n",
    "            num_layers=trg_nlayer,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        ).cuda()\n",
    "        \n",
    "        self.src2trg = torch.nn.Linear(\n",
    "            src_hidden_dim*self.n_directions,\n",
    "            trg_hidden_dim\n",
    "        ).cuda()\n",
    "        \n",
    "        self.trg2vocab = torch.nn.Linear(\n",
    "            trg_hidden_dim,\n",
    "            trg_vocab_size\n",
    "        ).cuda()\n",
    "        \n",
    "        # init weights\n",
    "        torch.nn.init.normal(self.src_embedding.weight, mean=0.0, std=0.02)\n",
    "        torch.nn.init.normal(self.trg_embedding.weight, mean=0.0, std=0.02)\n",
    "        torch.nn.init.constant(self.src2trg.bias, 0.0)\n",
    "        torch.nn.init.constant(self.trg2vocab.bias, 0.0)\n",
    "        \n",
    "    def forward(self, input_src, input_trg):\n",
    "        # init state\n",
    "        src_emb = self.src_embedding(input_src)\n",
    "        trg_emb = self.trg_embedding(input_trg)\n",
    "        \n",
    "        batch_size = input_src.size(1)\n",
    "        if self.encoder.batch_first:\n",
    "            batch_size = input_src.size(0)\n",
    "            \n",
    "        src_h_0 = Variable(torch.zeros(\n",
    "            self.encoder.num_layers*self.n_directions,\n",
    "            batch_size,\n",
    "            self.src_hidden_dim\n",
    "        )).cuda()\n",
    "        \n",
    "        src_c_0 = Variable(torch.zeros(\n",
    "            self.encoder.num_layers*self.n_directions,\n",
    "            batch_size,\n",
    "            self.src_hidden_dim\n",
    "        )).cuda()\n",
    "                \n",
    "        src_h, (src_h_t, src_c_t) = self.encoder(\n",
    "            src_emb,\n",
    "            (src_h_0, src_c_0)\n",
    "        )\n",
    "        \n",
    "        if self.src_bidirect:\n",
    "            h_t = torch.cat((src_h_t[-1], src_h_t[-2]), 1)\n",
    "            c_t = torch.cat((src_c_t[-1], src_c_t[-2]), 1)\n",
    "        else:\n",
    "            h_t = src_h_t[-1]\n",
    "            c_t = src_c_t[-1]\n",
    "            \n",
    "        trg_init_state = self.src2trg(h_t)\n",
    "        trg_init_state = torch.nn.Tanh()(trg_init_state)\n",
    "\n",
    "        trg_h_0 = trg_init_state.view(\n",
    "            self.decoder.num_layers,\n",
    "            trg_init_state.size(0),\n",
    "            trg_init_state.size(1)\n",
    "        )\n",
    "        trg_c_0 = c_t.view(\n",
    "            self.decoder.num_layers,\n",
    "            c_t.size(0),\n",
    "            c_t.size(1)\n",
    "        )\n",
    "        \n",
    "        trg_h, (_, _) = self.decoder(\n",
    "            trg_emb,\n",
    "            (trg_h_0, trg_c_0)\n",
    "        )\n",
    "        \n",
    "        trg_h_reshape = trg_h.contiguous().view(\n",
    "            trg_h.size(0)*trg_h.size(1),\n",
    "            trg_h.size(2)\n",
    "        )\n",
    "                \n",
    "        decoder_output = self.trg2vocab(trg_h_reshape)\n",
    "        decoder_output = decoder_output.view(\n",
    "            trg_h.size(0),\n",
    "            trg_h.size(1),\n",
    "            decoder_output.size(1)\n",
    "        )\n",
    "        \n",
    "        return decoder_output\n",
    "    \n",
    "    def decode(self, logits):\n",
    "        logits_reshape = logits.view(-1, self.trg_vocab_size)\n",
    "        word_probs = torch.nn.functional.softmax(logits_reshape)\n",
    "        word_probs = word_probs.view(\n",
    "            logits.size()[0], logits.size()[1], logits.size()[2]\n",
    "        )\n",
    "        return word_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary size: 80475\n",
      "The number of batches: 1444\n",
      "epoch=0 batch=0 loss=11.2938375473\n",
      "1993 overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding overcrowding\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../sum_data/'\n",
    "file_vocab = 'cnn_vocab.txt'\n",
    "file_corpus = 'cnn.txt'\n",
    "n_epoch = 1\n",
    "batch_size = 64\n",
    "\n",
    "vocab2id, id2vocab = construct_vocab(data_dir+'/'+file_vocab)\n",
    "print 'The vocabulary size: {0}'.format(len(vocab2id))\n",
    "\n",
    "n_batch = create_batch_file(file_name='../sum_data/cnn.txt', batch_size=batch_size)\n",
    "print 'The number of batches: {0}'.format(n_batch)\n",
    "\n",
    "model = seq2seq(\n",
    "    src_emb_dim=100,\n",
    "    trg_emb_dim=100,\n",
    "    src_hidden_dim=25,\n",
    "    trg_hidden_dim=50,\n",
    "    src_vocab_size=len(vocab2id),\n",
    "    trg_vocab_size=len(vocab2id),\n",
    "    src_pad_token=0,\n",
    "    trg_pad_token=0,\n",
    "    src_nlayer=2,\n",
    "    trg_nlayer=1,\n",
    "    src_bidirect=True,\n",
    "    batch_size=batch_size,\n",
    "    dropout=0.0\n",
    ").cuda()\n",
    "\n",
    "weight_mask = torch.ones(len(vocab2id)).cuda()\n",
    "weight_mask[vocab2id['<pad>']] = 0\n",
    "loss_criterion = torch.nn.CrossEntropyLoss(weight=weight_mask).cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "out_dir = 'results'\n",
    "if os.path.exists(out_dir):\n",
    "    shutil.rmtree(out_dir)\n",
    "os.mkdir(out_dir)\n",
    "losses = []\n",
    "for epoch in range(n_epoch):\n",
    "    for batch_id in range(n_batch):\n",
    "        src_var, trg_input_var, trg_output_var = process_minibatch(\n",
    "            batch_id, vocab2id, max_lens=[512, 64]\n",
    "        )\n",
    "        logits = model(src_var.cuda(), trg_input_var.cuda())\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = loss_criterion(\n",
    "            logits.contiguous().view(-1, len(vocab2id)),\n",
    "            trg_output_var.view(-1).cuda()\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append([epoch, batch_id, loss.data.cpu().numpy()[0]])\n",
    "        if batch_id % 100 == 0:\n",
    "            loss_np = np.array(losses)\n",
    "            np.save(out_dir+'/loss', loss_np)\n",
    "            \n",
    "            print 'epoch={0} batch={1} loss={2}'.format(\n",
    "                epoch, batch_id, loss.data.cpu().numpy()[0]\n",
    "            )\n",
    "            word_prob = model.decode(logits).data.cpu().numpy().argmax(axis=2)\n",
    "            sen_pred = [id2vocab[x] for x in word_prob[0]]\n",
    "            st_idx = len(sen_pred)\n",
    "            for k, wd in enumerate(sen_pred):\n",
    "                if wd == '</s>':\n",
    "                    st_idx = k\n",
    "                    break\n",
    "            sen_pred = sen_pred[:st_idx]\n",
    "            print ' '.join(sen_pred)\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                open(os.path.join(out_dir, 'lstm2lstm_'+str(epoch)+'_'+str(batch_id)+'.model'), 'w')\n",
    "            )\n",
    "            break\n",
    "                        \n",
    "shutil.rmtree('batch_folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clocks 'historic genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy genealogy\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(out_dir+'/00.model'))\n",
    "word_prob = model.decode(logits).data.cpu().numpy().argmax(axis=2)\n",
    "sen_pred = [id2vocab[x] for x in word_prob[0]]\n",
    "st_idx = len(sen_pred)\n",
    "for k, wd in enumerate(sen_pred):\n",
    "    if wd == '</s>':\n",
    "        st_idx = k\n",
    "        break\n",
    "sen_pred = sen_pred[:st_idx]\n",
    "print ' '.join(sen_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.        ,   0.        ,  11.29383755]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('results/loss.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
