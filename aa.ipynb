{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import argparse\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "class SoftDotAttention(torch.nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size\n",
    "    ):\n",
    "        super(SoftDotAttention, self).__init__()\n",
    "        \n",
    "        self.linear_in = torch.nn.Linear(\n",
    "            hidden_size,\n",
    "            hidden_size,\n",
    "            bias=False\n",
    "        )\n",
    "        self.softmax_ = torch.nn.Softmax()\n",
    "        self.linear_out = torch.nn.Linear(\n",
    "            hidden_size*2,\n",
    "            hidden_size,\n",
    "            bias=False\n",
    "        )\n",
    "        self.tanh_ = torch.nn.Tanh()\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, input_, context):\n",
    "        \n",
    "        target = self.linear_in(input_).unsqueeze(2)\n",
    "        \n",
    "        print context.size()\n",
    "        attn = torch.bmm(context, target).squeeze(2)\n",
    "        attn = self.softmax_(attn)\n",
    "        \n",
    "        return \n",
    "\n",
    "rd1 = Variable(torch.rand([10, 4]))\n",
    "rd2 = Variable(torch.rand([10, 1, 4]))\n",
    "model = SoftDotAttention(hidden_size=4)\n",
    "model(rd1, rd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary size: 80475\n",
      "The number of batches: 1444\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../sum_data/'\n",
    "file_vocab = 'cnn_vocab.txt'\n",
    "file_corpus = 'cnn.txt'\n",
    "n_epoch = 20\n",
    "batch_size = 64\n",
    "\n",
    "vocab2id, id2vocab = construct_vocab(data_dir+'/'+file_vocab)\n",
    "print 'The vocabulary size: {0}'.format(len(vocab2id))\n",
    "\n",
    "n_batch = create_batch_file(file_name='../sum_data/cnn.txt', batch_size=batch_size)\n",
    "print 'The number of batches: {0}'.format(n_batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0 ,.,.) = \n",
      "  0.4524  0.3267  0.3612  0.1276\n",
      "  0.6911  0.1173  0.3906  0.4915\n",
      "  0.9775  0.8692  0.5464  0.2167\n",
      "\n",
      "(1 ,.,.) = \n",
      "  0.2498  0.3740  0.1371  0.4953\n",
      "  0.4477  0.2291  0.5946  0.0385\n",
      "  0.0595  0.2777  0.1282  0.1308\n",
      "\n",
      "(2 ,.,.) = \n",
      "  0.7180  0.2005  0.8887  0.6670\n",
      "  0.0028  0.6183  0.7131  0.9975\n",
      "  0.1788  0.4824  0.4547  0.1755\n",
      "\n",
      "(3 ,.,.) = \n",
      "  0.5316  0.5623  0.5602  0.2228\n",
      "  0.6682  0.2707  0.3992  0.0777\n",
      "  0.6053  0.4470  0.5499  0.4378\n",
      "\n",
      "(4 ,.,.) = \n",
      "  0.0915  0.0009  0.2707  0.0755\n",
      "  0.7214  0.4176  0.2227  0.4667\n",
      "  0.6829  0.3640  0.2738  0.2508\n",
      "\n",
      "(5 ,.,.) = \n",
      "  0.7206  0.4302  0.2738  0.6968\n",
      "  0.7333  0.9302  0.1618  0.2182\n",
      "  0.3929  0.8321  0.7250  0.5763\n",
      "\n",
      "(6 ,.,.) = \n",
      "  0.6652  0.3046  0.0167  0.8674\n",
      "  0.3814  0.1642  0.9405  0.2781\n",
      "  0.9898  0.8735  0.5222  0.4309\n",
      "\n",
      "(7 ,.,.) = \n",
      "  0.5327  0.0764  0.6956  0.4435\n",
      "  0.9135  0.8709  0.1748  0.1000\n",
      "  0.3046  0.4527  0.0751  0.4540\n",
      "\n",
      "(8 ,.,.) = \n",
      "  0.3599  0.8564  0.3116  0.6819\n",
      "  0.2630  0.5872  0.0581  0.8738\n",
      "  0.9057  0.8298  0.6223  0.6964\n",
      "\n",
      "(9 ,.,.) = \n",
      "  0.4747  0.5113  0.1579  0.5506\n",
      "  0.8244  0.4299  0.9851  0.6679\n",
      "  0.2728  0.7524  0.1544  0.5604\n",
      "[torch.FloatTensor of size 10x3x4]\n",
      "\n",
      "\n",
      "(0 ,.,.) = \n",
      "  0.9234  0.5292  0.5342  0.9437  0.5002\n",
      "  0.5091  0.4063  0.7384  0.7919  0.8313\n",
      "  0.4877  0.1020  0.9152  0.7887  0.6800\n",
      "\n",
      "(1 ,.,.) = \n",
      "  0.4540  0.7985  0.5618  0.9952  0.0114\n",
      "  0.5331  0.5020  0.4148  0.5241  0.4455\n",
      "  0.8084  0.1099  0.8999  0.9505  0.6561\n",
      "\n",
      "(2 ,.,.) = \n",
      "  0.6284  0.9971  0.6055  0.3082  0.2288\n",
      "  0.9764  0.0021  0.6280  0.2671  0.3800\n",
      "  0.0710  0.6256  0.8445  0.6524  0.9350\n",
      "\n",
      "(3 ,.,.) = \n",
      "  0.1997  0.3623  0.5476  0.2653  0.2570\n",
      "  0.4270  0.2667  0.7277  0.0425  0.6057\n",
      "  0.4693  0.7568  0.5659  0.7761  0.9482\n",
      "\n",
      "(4 ,.,.) = \n",
      "  0.1814  0.6622  0.0646  0.5165  0.8559\n",
      "  0.4589  0.4485  0.5481  0.4323  0.4356\n",
      "  0.0831  0.6459  0.5109  0.3624  0.8981\n",
      "\n",
      "(5 ,.,.) = \n",
      "  0.0478  0.5292  0.3339  0.0292  0.3525\n",
      "  0.5155  0.0381  0.5564  0.5412  0.2734\n",
      "  0.1010  0.1461  0.3119  0.6187  0.1288\n",
      "\n",
      "(6 ,.,.) = \n",
      "  0.0741  0.9033  0.6035  0.1095  0.2640\n",
      "  0.1763  0.8006  0.1907  0.6215  0.9406\n",
      "  0.5986  0.3568  0.1800  0.9102  0.8884\n",
      "\n",
      "(7 ,.,.) = \n",
      "  0.7719  0.9924  0.7410  0.9021  0.4205\n",
      "  0.7675  0.6622  0.0184  0.7000  0.8742\n",
      "  0.8957  0.8432  0.8320  0.6551  0.1221\n",
      "\n",
      "(8 ,.,.) = \n",
      "  0.4207  0.0323  0.9538  0.1614  0.5147\n",
      "  0.4307  0.9214  0.0688  0.3785  0.3356\n",
      "  0.6957  0.4377  0.4797  0.2868  0.2107\n",
      "\n",
      "(9 ,.,.) = \n",
      "  0.8630  0.4479  0.2887  0.5391  0.5851\n",
      "  0.0799  0.4794  0.3877  0.0736  0.5948\n",
      "  0.9951  0.9621  0.1712  0.5578  0.4385\n",
      "[torch.FloatTensor of size 10x3x5]\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "torch.mm received an invalid combination of arguments - got (torch.FloatTensor, Variable), but expected one of:\n * (torch.FloatTensor source, torch.FloatTensor mat2)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mtorch.FloatTensor\u001b[0m, \u001b[31;1mVariable\u001b[0m)\n * (torch.SparseFloatTensor source, torch.FloatTensor mat2)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.FloatTensor\u001b[0m, \u001b[31;1mVariable\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-908bc22ffa54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mrd2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSoftDotAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrd1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrd2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m '''\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-908bc22ffa54>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_, context)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;31m#attn = torch.bmm(context, target).squeeze(2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m#attn = self.softmax_(attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/linear.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/tensor.pyc\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         See :func:`torch.matmul`.\"\"\"\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/functional.pyc\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(tensor1, tensor2, out)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_contiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: torch.mm received an invalid combination of arguments - got (torch.FloatTensor, Variable), but expected one of:\n * (torch.FloatTensor source, torch.FloatTensor mat2)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mtorch.FloatTensor\u001b[0m, \u001b[31;1mVariable\u001b[0m)\n * (torch.SparseFloatTensor source, torch.FloatTensor mat2)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.FloatTensor\u001b[0m, \u001b[31;1mVariable\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "class SoftDotAttention(torch.nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size\n",
    "    ):\n",
    "        super(SoftDotAttention, self).__init__()\n",
    "        \n",
    "        self.linear_in = torch.nn.Linear(\n",
    "            hidden_size,\n",
    "            hidden_size,\n",
    "            bias=False\n",
    "        )\n",
    "        self.softmax_ = torch.nn.Softmax()\n",
    "        self.linear_out = torch.nn.Linear(\n",
    "            hidden_size*2,\n",
    "            hidden_size,\n",
    "            bias=False\n",
    "        )\n",
    "        self.tanh_ = torch.nn.Tanh()\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, input_, context):\n",
    "        \n",
    "        print input_\n",
    "        print context\n",
    "        target = self.linear_in(input_)\n",
    "        #attn = torch.bmm(context, target).squeeze(2)\n",
    "        #attn = self.softmax_(attn)\n",
    "        \n",
    "        return\n",
    "\n",
    "rd1 = torch.rand([10, 3, 4])\n",
    "rd2 = torch.rand([10, 3, 5])\n",
    "model = SoftDotAttention(hidden_size=10)\n",
    "model(rd1, rd2)\n",
    "        \n",
    "'''\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      "  1\n",
      "  2\n",
      "\n",
      "(1 ,.,.) = \n",
      "  3\n",
      "  4\n",
      "[torch.LongTensor of size 2x2x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "db = Variable(torch.LongTensor([[1,2],[3,4]]))\n",
    "db = db.unsqueeze(2)\n",
    "print db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq2seqAttention (\n",
      "  (src_embedding): Embedding(999, 100, padding_idx=0)\n",
      "  (trg_embedding): Embedding(999, 100, padding_idx=0)\n",
      "  (encoder): LSTM(100, 25, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (decoder): LSTMAttentionDot (\n",
      "  )\n",
      "  (encoder2decoder): Linear (50 -> 50)\n",
      "  (decoder2vocab): Linear (50 -> 999)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LSTMAttentionDot(torch.nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        num_layers=1,\n",
    "        batch_first=True\n",
    "    ):\n",
    "        super(LSTMAttentionDot, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layer = num_layers\n",
    "        \n",
    "    def forward(self):\n",
    "        \n",
    "        \n",
    "        return\n",
    "    \n",
    "\n",
    "class seq2seqAttention(torch.nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        src_emb_dim=100,\n",
    "        trg_emb_dim=100,\n",
    "        src_hidden_dim=50,\n",
    "        trg_hidden_dim=50,\n",
    "        src_vocab_size=999,\n",
    "        trg_vocab_size=999,\n",
    "        src_pad_token=0,\n",
    "        trg_pad_token=0,\n",
    "        src_nlayer=2,\n",
    "        trg_nlayer=1,\n",
    "        batch_first=True,\n",
    "        src_bidirect=True,\n",
    "        batch_size=128,\n",
    "        dropout=0.0\n",
    "    ):\n",
    "        super(seq2seqAttention, self).__init__()\n",
    "        # parameters\n",
    "        self.src_emb_dim = src_emb_dim\n",
    "        self.trg_emb_dim = trg_emb_dim\n",
    "        self.src_hidden_dim = src_hidden_dim\n",
    "        self.trg_hidden_dim = trg_hidden_dim\n",
    "        self.src_vocab_size = src_vocab_size\n",
    "        self.trg_vocab_size = trg_vocab_size\n",
    "        self.src_nlayer = src_nlayer\n",
    "        self.trg_nlayer = trg_nlayer\n",
    "        self.batch_first = batch_first\n",
    "        self.src_bidirect = src_bidirect\n",
    "        self.batch_size = batch_size\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.src_num_directions = 1\n",
    "        if self.src_bidirect:\n",
    "            self.src_hidden_dim = src_hidden_dim // 2\n",
    "            self.src_num_directions = 2\n",
    "        \n",
    "        \n",
    "        # source embedding\n",
    "        self.src_embedding = torch.nn.Embedding(\n",
    "            self.src_vocab_size,\n",
    "            self.src_emb_dim,\n",
    "            padding_idx=0\n",
    "        ).cuda()\n",
    "        torch.nn.init.normal(\n",
    "            self.src_embedding.weight, \n",
    "            mean=0.0, \n",
    "            std=0.02\n",
    "        )\n",
    "        # targe embedding\n",
    "        self.trg_embedding = torch.nn.Embedding(\n",
    "            self.trg_vocab_size,\n",
    "            self.trg_emb_dim,\n",
    "            padding_idx=0\n",
    "        ).cuda()\n",
    "        torch.nn.init.normal(\n",
    "            self.trg_embedding.weight,\n",
    "            mean=0.0,\n",
    "            std=0.02\n",
    "        )\n",
    "        # encoder\n",
    "        self.encoder = torch.nn.LSTM(\n",
    "            input_size=self.src_emb_dim,\n",
    "            hidden_size=self.src_hidden_dim,\n",
    "            num_layers=self.src_nlayer,\n",
    "            batch_first=self.batch_first,\n",
    "            dropout=self.dropout,\n",
    "            bidirectional=self.src_bidirect\n",
    "        ).cuda()\n",
    "        # decoder\n",
    "        self.decoder = LSTMAttentionDot(\n",
    "            input_size=self.trg_emb_dim,\n",
    "            hidden_size=self.trg_hidden_dim,\n",
    "            batch_first=self.batch_first\n",
    "        ).cuda()\n",
    "        \n",
    "        # encoder to decoder\n",
    "        self.encoder2decoder = torch.nn.Linear(\n",
    "            self.src_hidden_dim*self.src_num_directions,\n",
    "            self.trg_hidden_dim\n",
    "        ).cuda()\n",
    "        torch.nn.init.constant(self.encoder2decoder.bias, 0.0)\n",
    "        # decoder to vocab\n",
    "        self.decoder2vocab = torch.nn.Linear(\n",
    "            self.trg_hidden_dim,\n",
    "            self.trg_vocab_size\n",
    "        ).cuda()\n",
    "        torch.nn.init.constant(self.decoder2vocab.bias, 0.0)\n",
    "        \n",
    "        \n",
    "    def forward(self, input_src, input_trg):\n",
    "        \n",
    "        src_emb = self.src_embedding(input_src)\n",
    "        trg_emb = self.trg_embedding(input_trg)\n",
    "        \n",
    "        batch_size = input_src.size(1)\n",
    "        if self.batch_first:\n",
    "            batch_size = input_src.size(0)\n",
    "        \n",
    "        \n",
    "        return\n",
    "    \n",
    "\n",
    "model = seq2seqAttention(\n",
    "    src_emb_dim=100,\n",
    "    trg_emb_dim=100,\n",
    "    src_hidden_dim=50,\n",
    "    trg_hidden_dim=50,\n",
    "    src_vocab_size=999,\n",
    "    trg_vocab_size=999,\n",
    "    src_pad_token=0,\n",
    "    trg_pad_token=0,\n",
    "    src_nlayer=2,\n",
    "    trg_nlayer=1,\n",
    "    batch_first=True,\n",
    "    src_bidirect=True,\n",
    "    batch_size=128,\n",
    "    dropout=0.0\n",
    ").cuda()\n",
    "\n",
    "print model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.4915 -0.0945  0.0530  ...   0.2648 -0.3031 -0.1796\n",
      " -0.1721 -0.0270  0.1237  ...   0.2096 -0.2915 -0.2141\n",
      " -0.0334  0.0542  0.1774  ...   0.1599 -0.2373 -0.0898\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0456  0.3876  0.0400  ...   0.1950 -0.3162 -0.1525\n",
      "  0.0561  0.1713  0.1334  ...   0.1987 -0.2758 -0.1507\n",
      "  0.0935  0.0988  0.1762  ...   0.4046 -0.1447 -0.0750\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0824  0.0533 -0.0439  ...   0.2430 -0.1623 -0.1258\n",
      " -0.0391  0.1295  0.1469  ...   0.2685 -0.1236 -0.1290\n",
      "  0.0079  0.1338  0.2233  ...   0.4243 -0.0532 -0.0658\n",
      "... \n",
      "\n",
      "(125,.,.) = \n",
      "  0.0750  0.1155  0.2895  ...   0.2027 -0.2866 -0.0849\n",
      "  0.0663  0.1225  0.3103  ...   0.2528 -0.2727  0.0233\n",
      "  0.0854  0.1500  0.2596  ...   0.4361 -0.1067  0.1449\n",
      "\n",
      "(126,.,.) = \n",
      "  0.1315  0.1835 -0.1146  ...   0.2034 -0.2275 -0.1422\n",
      "  0.1445  0.1585  0.0511  ...   0.1639 -0.2089 -0.1456\n",
      "  0.1089  0.1582  0.2148  ...  -0.0072 -0.1570 -0.0623\n",
      "\n",
      "(127,.,.) = \n",
      " -0.0824 -0.3411  0.1124  ...   0.1433 -0.3878 -0.1323\n",
      " -0.0717 -0.2674  0.1392  ...   0.2340 -0.4021 -0.1452\n",
      " -0.0508 -0.2317  0.1510  ...   0.3596 -0.2464 -0.1045\n",
      "[torch.FloatTensor of size 128x3x10]\n",
      "\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  0.1278 -0.4344 -0.0333  0.0542 -0.1171\n",
      " -0.0723 -0.1943 -0.0918  0.0767 -0.1569\n",
      "  0.0536  0.0136 -0.0059 -0.0972 -0.2858\n",
      "                   ⋮                    \n",
      " -0.3506 -0.2966  0.3913  0.1763 -0.2412\n",
      " -0.1712 -0.0628  0.1009 -0.0929 -0.2692\n",
      "  0.1719  0.2384  0.1346 -0.1445  0.0922\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.1826 -0.0732 -0.3008  0.2330 -0.2283\n",
      " -0.2206 -0.0678  0.2528  0.1373 -0.0292\n",
      " -0.2065 -0.2510 -0.3330  0.0959 -0.1374\n",
      "                   ⋮                    \n",
      "  0.0463  0.1171  0.0891 -0.0246 -0.0568\n",
      " -0.2242 -0.0341  0.0032  0.1520  0.0446\n",
      " -0.1841  0.0820  0.2794  0.1347 -0.2328\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0334  0.0542  0.1774 -0.2411  0.0675\n",
      "  0.0935  0.0988  0.1762 -0.3285  0.0941\n",
      "  0.0079  0.1338  0.2233 -0.3799  0.0482\n",
      "                   ⋮                    \n",
      "  0.0854  0.1500  0.2596 -0.0747  0.1204\n",
      "  0.1089  0.1582  0.2148 -0.4012  0.0232\n",
      " -0.0508 -0.2317  0.1510 -0.1604  0.1933\n",
      "\n",
      "( 3 ,.,.) = \n",
      " -0.0795  0.0848  0.2648 -0.3031 -0.1796\n",
      "  0.1455  0.1251  0.1950 -0.3162 -0.1525\n",
      " -0.0764  0.0705  0.2430 -0.1623 -0.1258\n",
      "                   ⋮                    \n",
      " -0.0402  0.0761  0.2027 -0.2866 -0.0849\n",
      "  0.0923  0.1041  0.2034 -0.2275 -0.1422\n",
      "  0.1247  0.0217  0.1433 -0.3878 -0.1323\n",
      "[torch.FloatTensor of size 4x128x5]\n",
      "\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  0.5051 -0.5864 -0.1145  0.0694 -0.8837\n",
      " -0.1741 -0.6498 -0.1757  0.1528 -0.4771\n",
      "  0.1401  0.0444 -0.0264 -0.1877 -0.5731\n",
      "                   ⋮                    \n",
      " -0.6194 -0.5053  0.7390  0.4693 -1.0076\n",
      " -0.3524 -0.2660  0.1909 -0.3293 -0.4239\n",
      "  0.4489  0.5301  0.3638 -0.1942  0.4106\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.4839 -0.1110 -0.4291  0.6640 -0.7604\n",
      " -0.5822 -0.0834  0.3784  0.3655 -0.1395\n",
      " -0.5039 -0.2966 -0.5594  0.5026 -0.6740\n",
      "                   ⋮                    \n",
      "  0.1707  0.1882  0.2989 -0.0561 -0.1252\n",
      " -0.7190 -0.0426  0.0058  0.4557  0.1399\n",
      " -0.4628  0.1237  1.2600  0.2892 -0.7469\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0998  0.1446  0.5210 -0.4139  0.1402\n",
      "  0.3429  0.2386  0.4438 -0.5319  0.1728\n",
      "  0.0275  0.2859  0.6047 -0.5956  0.0943\n",
      "                   ⋮                    \n",
      "  0.3021  0.3427  0.9476 -0.1355  0.2555\n",
      "  0.3685  0.3562  0.4437 -0.6332  0.0484\n",
      " -0.1402 -0.5679  0.3474 -0.2660  0.3682\n",
      "\n",
      "( 3 ,.,.) = \n",
      " -0.1765  0.2419  0.3912 -0.6507 -0.4059\n",
      "  0.3743  0.3107  0.2984 -0.5919 -0.3127\n",
      " -0.1792  0.1630  0.3616 -0.3351 -0.2791\n",
      "                   ⋮                    \n",
      " -0.0983  0.1691  0.3071 -0.5952 -0.1891\n",
      "  0.2555  0.2345  0.3019 -0.4485 -0.3183\n",
      "  0.3458  0.0567  0.2013 -0.8333 -0.2848\n",
      "[torch.FloatTensor of size 4x128x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnn = torch.nn.LSTM(9, 5, num_layers=2, bidirectional=True, batch_first=True)\n",
    "\n",
    "input = Variable(torch.randn(128, 3, 9))\n",
    "h0 = Variable(torch.randn(4, 128, 5))\n",
    "c0 = Variable(torch.randn(4, 128, 5))\n",
    "output, hn = rnn(input, (h0, c0))\n",
    "print output\n",
    "print hn[0]\n",
    "print hn[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
